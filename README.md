# High-Dimensional-ETL-Pipeline-with-Memory-Constraints
A scalable Python-based ETL pipeline that processes large datasets in chunks, computes running statistics, normalizes data, and writes fault-tolerant Parquet outputs with checkpointing.
